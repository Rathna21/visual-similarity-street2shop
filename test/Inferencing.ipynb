{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Necessary imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tensorflow as tf\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from utils import load_old_model, get_image_features, get_result\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "from annoy import AnnoyIndex\n",
    "import random\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Config GPU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CUDA_DEVICE_ORDER\"] = \"PCI_BUS_ID\"\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"3\"\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.1\n",
    "set_session(tf.Session(config=config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load necessary files from disk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./full_catalog_images.pkl', 'rb') as f:\n",
    "    full_catalog_images = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./street_images.pkl', 'rb') as f:\n",
    "    street_images = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./bbox_mappings_streetImg.pkl', 'rb') as f:\n",
    "    bbox_mappings = pickle.load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "triplet_model = load_old_model('Your model path')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate embedding space for the test images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = {}\n",
    "for index, row in full_catalog_images.iterrows():\n",
    "    if index % 500 == 0:\n",
    "        print(str(index) + ' of ' + str(len(full_catalog_images)))\n",
    "    img_path = row['file_path']\n",
    "    img = np.array(Image.open(img_path))\n",
    "    image_features = get_image_features(triplet_model, img, N=2048)\n",
    "    embeddings[index] = image_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Annoy Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_index = AnnoyIndex(N, metric='euclidean')\n",
    "for i, embedding in embeddings.items():\n",
    "    search_index.add_item(i, embedding)  \n",
    "search_index.build(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'path to your street images'\n",
    "\n",
    "for i, image in enumerate(street_images):\n",
    "    \n",
    "    q_img = os.path.join(Path, image)\n",
    "    if os.path.isfile(q_img):\n",
    "        bbox = bbox_mappings[i]\n",
    "        \n",
    "        left = bbox['left']\n",
    "        top = bbox['top']\n",
    "        right = left + bbox['width']\n",
    "        bottom = top + bbox['height']\n",
    "        \n",
    "        query_img = Image.open(q_img)\n",
    "        \n",
    "        query_crop = query_img.crop((left, top, right, bottom))\n",
    "        query = np.array(query_crop.resize((300,300), Image.NEAREST))\n",
    "        \n",
    "        image_embeddings = get_image_features(triplet_model, query_array)\n",
    "        kNN_results = get_result(image_embeddings, search_index, k=10, query_index=q_index)\n",
    "        print(kNN_results)\n",
    "        \n",
    "        fig, ax = plt.subplots(1, 11, figsize=(25, 25))\n",
    "        ax[0].imshow(img)\n",
    "        ax[0].set_title(f'query_image, id={i}')\n",
    "\n",
    "        for i, ax in enumerate(ax.flatten()[1:]):\n",
    "            ax.imshow(street_images[i])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
